# CD-MF-MDM-L2-02-度量数据采集和存储系统架构设计文档

<table border="0" bordercolor="#FFFFFF">
  <tr>
    <th><img alt="title pic" src="../../docs/imgs/DevOps流程/DevOps_Gears.png"></th>
    <th><h1 style="font-size:150%">能力项  [度量指标]</h1></th>
  </tr>
</table>

# 前言

度量指标(Metrics) : 指用于描述一个物体或事物的某个性质的指数、规格、标准，使其可以和其他的物体或者事物的提交。从软件的角度讲度量即把所有东西都量化、数据化、可采集。指标即表示对这些量化后的数据的目标值。维度即标识一个事物某一个侧面的一组指标。数据和度量则是帮助企业去发现DevOps转型过程中的瓶颈并且做出改进的关键基础。

# 目的

通过DevOps统一数据收集、展现、分析和告警平台可以在开发过程中避免潜在问题，从而降低成本，并确保及时高质量的发布。DevOps Dashboard可帮助提高 DevOps 实践的效率，从而加快软件的开发，改进应用交付，并持续提升性能，同时确保快速、准时发布，以实现业务目标。

# 数据收集展现整体架构

![devops metrics tools arch](../../docs/imgs/DevOps流程/devops_metrics_tools_arch.png)                               

**监控源**

数据来源大致可以分为三个部分：项目管理系统、自动化测试平台和运营系统。项目管理主要提供代码、Issue、里程碑，开发人员等信息，测试平台提供各种自动化质量测试系统的测试日志、结果等数据，运营系统提供应用运行时的各种数据。

**数据采集**

数据采集从数据源收集数据存入数据存储系统。数据采集从指标上划分可以分为研发指标、集成/测试指标、运营指标等。

研发指标如需求数量、需求状态、流水线执行状态/日志、代码提交状态等，集成/测试指标如：代码静态质量、单元/API测试覆盖率、代码Bug率、部署成功率、Bug修复周期等，运营指标如：CPU负载、内存负载、磁盘负载、网络IO、服务调用次数、访问量、服务可用性等。

从采集方式来说通常可以分为接口采集、客户端agent采集、通过网络协议主动抓取（http、snmp等）

**数据存储**

采集到的数据一般都会存储到文件系统（如HDFS）、索引系统（如elasticsearch）、指标库（如influxdb）、消息队列（如kafka，做消息临时存储或者缓冲）、数据库（如mysql）

**数据分析**

针对采集到的数据，进行数据的处理。处理分两类：实时处理和批处理。技术包括Map/Reduce计算、全日志检索、流式计算、指标计算等，重点是根据不同的场景需求选择不同的计算方式。

**数据展现**

将处理的结果进行图表展现，在多屏时代，跨设备的支持必不可少。

**预警**

如果在数据处理过程发现了问题，则需要进行异常的分析、风险的预估以及事件的触发或告警。

# 数据采集

## 读写API

数据采集实例收集业务相关数据，定时调用API接口收集数据。大部分DevOps服务组件都提供API获得服务数据，这个方法实现简单，对业务系统侵入小。缺点是占用服务资源，个别API在业务系统上开销较大，不建议频繁调用。

## 读取日志文件

日志的来源，日志的一般存储在三个位置：数据库、操作系统日志、日志文件。一般操作日志会习惯于存储在数据库中。Syslog、Rsyslog、Journald都是linux系统的日志服务。

日志的采集工作大都是通过客户端进行，客户端通过fluentd实现采集功能。fluentd是开源社区中流行的日志收集工具，fluentd基于CRuby实现，并对性能表现关键的一些组件用C语言重新实现，整体性能相当不错。优点是设计简洁，pipeline内数据传递可靠性高。缺点是相较于logstash和flume，其插件支持相对少一些，但在实践中基本够用了。

## 网络监控

通过端口监控、Ping监控、HTTP监控、网络监控等等来获取数据。这种监听式的采集，属于外挂式的采集。这类采集比较轻量，对系统的侵入性较小，通过简单的配置，可以快速的看到效果。除网络监控本身之外，这类监控有一个显著的特点，就是 严重依赖网络，一旦网络有抖动，极易发生误报。因此可以采取多点探测的方式，这样可以在一定程度上防止误报的发生。

# 数据存储分析

在大批量的监控数据涌过来后，考虑到网络的压力和数据处理的瓶颈，一般会在存储前先经过一层数据缓冲，将采集到的数据先放置到消息队列中，然后再从分布式队列中读取数据并存储。

存储和分析息息相关，监控数据的处理通常分为实时处理和非实时处理（如大数据的批处理框架hadoop等），如Elasticsearch就是一个实时的分布式搜索和分析引擎，它可以用于全文搜索，结构化搜索以及分析。

Elasticsearch 是一个实时的分布式搜索和分析引擎，它可以用于全文搜索，结构化搜索以及分析。它是一个建立在全文搜索引擎 Apache Lucene 基础上的搜索引擎，使用 Java 语言编写。

主要特点如下：

·    实时分析

·    分布式实时文件存储，并将每一个字段都编入索引

·    文档导向，所有的对象全部是文档

·    高可用性，易扩展，支持集群（Cluster）、分片和复制（Shards 和 Replicas） 接口友好，支持 JSON

·    检索性能强大，ES基于lucene,对于每个新写入的数据，会针对于每个字段都创建索引

# 数据展现

Kibana为 Elasticsearch 提供分析和可视化的 Web 平台。它可以在 Elasticsearch 的索引中查找，交互数据，并生成各种维度的表图。Kibana和Elasticsearch可以说是无缝衔接，再加上fluentd，组成的EFK赫赫有名，很多企业都会直接采用这一种框架。一般情况下Kibana能满足大部分的监控需求，但是其只能依靠现有的数据进行展现，如果需要和外部数据结合处理，就会无法满足了

在实践过程中构建统一监控平台时，需要将日志和性能等监控数据结合预警中心等统一展现，所以对于kibana的替换就无法避免了。我们是通过使用JAVA去查询Elasticsearch的数据，结合其他数据统一分析，将展现的结果进行滚动展现或者用图表显示。